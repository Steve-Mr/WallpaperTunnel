{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/quantization/preprocess.py\", line 127, in <module>\n",
      "    quant_pre_process(\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/quantization/shape_inference.py\", line 71, in quant_pre_process\n",
      "    model = SymbolicShapeInference.infer_shapes(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/tools/symbolic_shape_infer.py\", line 2822, in infer_shapes\n",
      "    raise Exception(\"Incomplete symbolic shape inference\")\n",
      "Exception: Incomplete symbolic shape inference\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.quantization.preprocess --input realesrgan-anime_with_pre_post_processing.onnx --output anime-infer.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Failed to infer data type of tensor: _ppp1_data_with_reversed_axis. Please add data type info for this tensor if your model has customized operators.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'realesrgan-2k_with_pre_post_processing.onnx'\n",
    "model_quant = '2k.quant.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting models with optimization style 'Fixed' and level 'all'\n",
      "Converting optimized ONNX model /home/maary/Build/Real-ESRGAN/anime.quant.onnx to ORT format model /home/maary/Build/Real-ESRGAN/anime.quant.ort\n",
      "Error converting /home/maary/Build/Real-ESRGAN/anime.quant.onnx: [ONNXRuntimeError] : 1 : FAIL : Load model from /home/maary/Build/Real-ESRGAN/anime.quant.onnx failed:Fatal error: com.microsoft.extensions:DecodeImage(-1) is not a registered function/op\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/tools/convert_onnx_models_to_ort.py\", line 372, in <module>\n",
      "    convert_onnx_models_to_ort(\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/tools/convert_onnx_models_to_ort.py\", line 310, in convert_onnx_models_to_ort\n",
      "    converted_models = _convert(\n",
      "                       ^^^^^^^^^\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/tools/convert_onnx_models_to_ort.py\", line 158, in _convert\n",
      "    _ = ort.InferenceSession(\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 419, in __init__\n",
      "    self._create_inference_session(providers, provider_options, disabled_optimizers)\n",
      "  File \"/home/maary/anaconda3/envs/yolov5/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 452, in _create_inference_session\n",
      "    sess = C.InferenceSession(session_options, self._model_path, True, self._read_config_from_model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Load model from /home/maary/Build/Real-ESRGAN/anime.quant.onnx failed:Fatal error: com.microsoft.extensions:DecodeImage(-1) is not a registered function/op\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.tools.convert_onnx_models_to_ort anime.quant.onnx --target_platform arm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
